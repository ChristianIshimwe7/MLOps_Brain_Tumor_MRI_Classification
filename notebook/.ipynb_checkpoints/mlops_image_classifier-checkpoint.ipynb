{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d15897-f3ef-4eb9-9f53-ca7f6d1528af",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# MLOps Image Classification - Full Pipeline\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Objective**: Train, evaluate, deploy, retrain, and scale a CNN on image data.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Data**: 28×28 grayscale images (horizontal vs vertical lines)\\n\",\n",
    "    \"**Model**: Fine-tuned ResNet-18\\n\",\n",
    "    \"**Metrics**: Accuracy, Precision, Recall, F1, Loss\\n\",\n",
    "    \"**Optimization**: Adam + Weight Decay + LR Scheduler + Early Stopping\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import torch, torch.nn as nn, torch.optim as optim\\n\",\n",
    "    \"from torchvision import models, transforms\\n\",\n",
    "    \"from torch.utils.data import DataLoader, Dataset\\n\",\n",
    "    \"import numpy as np, matplotlib.pyplot as plt, os, json, sqlite3, seaborn as sns\\n\",\n",
    "    \"from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import warnings; warnings.filterwarnings('ignore')\\n\",\n",
    "    \"torch.manual_seed(42)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\"## 1. Data Acquisition & Processing\"]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def generate_image(label, size=28, noise=0.2):\\n\",\n",
    "    \"    img = np.random.rand(size, size) * noise\\n\",\n",
    "    \"    if label == 0:  # horizontal\\n\",\n",
    "    \"        img[size//2, :] = 1.0\\n\",\n",
    "    \"    else:           # vertical\\n\",\n",
    "    \"        img[:, size//2] = 1.0\\n\",\n",
    "    \"    return img\\n\",\n",
    "    \"\\n\",\n",
    "    \"def build_dataset(n_samples=2000):\\n\",\n",
    "    \"    X, y = [], []\\n\",\n",
    "    \"    for i in range(n_samples):\\n\",\n",
    "    \"        label = i % 2\\n\",\n",
    "    \"        X.append(generate_image(label))\\n\",\n",
    "    \"        y.append(label)\\n\",\n",
    "    \"    return np.array(X)[:, np.newaxis, :, :], np.array(y)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train, y_train = build_dataset(1600)\\n\",\n",
    "    \"X_test,  y_test  = build_dataset(400)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save sample images\\n\",\n",
    "    \"Path('data/train').mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"Path('data/test').mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"for i in range(50):\\n\",\n",
    "    \"    np.save(f'data/train/img_{i}.npy', X_train[i])\\n\",\n",
    "    \"    np.save(f'data/test/img_{i}.npy', X_test[i])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class LineDataset(Dataset):\\n\",\n",
    "    \"    def __init__(self, X, y, transform=None):\\n\",\n",
    "    \"        self.X = torch.FloatTensor(X)\\n\",\n",
    "    \"        self.y = torch.LongTensor(y)\\n\",\n",
    "    \"        self.transform = transform\\n\",\n",
    "    \"    def __len__(self): return len(self.y)\\n\",\n",
    "    \"    def __getitem__(self, idx):\\n\",\n",
    "    \"        img = self.X[idx]\\n\",\n",
    "    \"        if self.transform: img = self.transform(img)\\n\",\n",
    "    \"        return img, self.y[idx]\\n\",\n",
    "    \"\\n\",\n",
    "    \"transform = transforms.Compose([transforms.Normalize(mean=[0.5], std=[0.5])])\\n\",\n",
    "    \"train_ds = LineDataset(X_train, y_train, transform)\\n\",\n",
    "    \"test_ds  = LineDataset(X_test,  y_test,  transform)\\n\",\n",
    "    \"train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\\n\",\n",
    "    \"test_loader  = DataLoader(test_ds,  batch_size=64, shuffle=False)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\"## 2. Model: Fine-tune Pre-trained ResNet-18\"]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model = models.resnet18(pretrained=True)\\n\",\n",
    "    \"model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)\\n\",\n",
    "    \"model.fc = nn.Linear(model.fc.in_features, 2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\\n\",\n",
    "    \"model = model.to(device)\\n\",\n",
    "    \"\\n\",\n",
    "    \"criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\\n\",\n",
    "    \"scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.5)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\"## 3. Training with Early Stopping\"]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class EarlyStopping:\\n\",\n",
    "    \"    def __init__(self, patience=3, delta=0):\\n\",\n",
    "    \"        self.patience, self.delta, self.best = patience, delta, None\\n\",\n",
    "    \"        self.counter, self.early_stop = 0, False\\n\",\n",
    "    \"    def __call__(self, val_loss):\\n\",\n",
    "    \"        if self.best is None: self.best = val_loss; return\\n\",\n",
    "    \"        if val_loss < self.best - self.delta: self.best = val_loss; self.counter = 0\\n\",\n",
    "    \"        else: self.counter += 1\\n\",\n",
    "    \"        if self.counter >= self.patience: self.early_stop = True\\n\",\n",
    "    \"\\n\",\n",
    "    \"es = EarlyStopping(patience=3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def train_epoch():\\n\",\n",
    "    \"    model.train(); loss_sum = 0\\n\",\n",
    "    \"    for x, y in train_loader:\\n\",\n",
    "    \"        x, y = x.to(device), y.to(device)\\n\",\n",
    "    \"        optimizer.zero_grad()\\n\",\n",
    "    \"        out = model(x)\\n\",\n",
    "    \"        loss = criterion(out, y)\\n\",\n",
    "    \"        loss.backward()\\n\",\n",
    "    \"        optimizer.step()\\n\",\n",
    "    \"        loss_sum += loss.item() * x.size(0)\\n\",\n",
    "    \"    return loss_sum / len(train_loader.dataset)\\n\",\n",
    "    \"\\n\",\n",
    "    \"def eval_epoch():\\n\",\n",
    "    \"    model.eval(); preds, trues = [], []\\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        for x, y in test_loader:\\n\",\n",
    "    \"            x = x.to(device)\\n\",\n",
    "    \"            out = model(x)\\n\",\n",
    "    \"            preds.extend(out.argmax(dim=1).cpu().numpy())\\n\",\n",
    "    \"            trues.extend(y.numpy())\\n\",\n",
    "    \"    return preds, trues\\n\",\n",
    "    \"\\n\",\n",
    "    \"for epoch in range(20):\\n\",\n",
    "    \"    train_loss = train_epoch()\\n\",\n",
    "    \"    preds, trues = eval_epoch()\\n\",\n",
    "    \"    val_acc = accuracy_score(trues, preds)\\n\",\n",
    "    \"    scheduler.step(train_loss)\\n\",\n",
    "    \"    print(f'Epoch {epoch+1:02d} – loss {train_loss:.4f} – val_acc {val_acc:.4f}')\\n\",\n",
    "    \"    es(train_loss)\\n\",\n",
    "    \"    if es.early_stop: print('Early stopping!'); break\\n\",\n",
    "    \"\\n\",\n",
    "    \"Path('models').mkdir(exist_ok=True)\\n\",\n",
    "    \"torch.save(model.state_dict(), 'models/resnet_finetuned.pth')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\"## 4. Evaluation (5 Metrics)\"]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"preds, trues = eval_epoch()\\n\",\n",
    "    \"acc = accuracy_score(trues, preds)\\n\",\n",
    "    \"prec, rec, f1, _ = precision_recall_fscore_support(trues, preds, average='macro')\\n\",\n",
    "    \"print(f'Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | Loss: {train_loss:.4f}')\\n\",\n",
    "    \"\\n\",\n",
    "    \"cm = confusion_matrix(trues, preds)\\n\",\n",
    "    \"plt.figure(figsize=(5,4))\\n\",\n",
    "    \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\\n\",\n",
    "    \"plt.title('Confusion Matrix'); plt.xlabel('Pred'); plt.ylabel('True')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\"## 5. Visualizations (3 Features)\"]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 1. Sample Images\\n\",\n",
    "    \"fig, axs = plt.subplots(1,3, figsize=(9,3))\\n\",\n",
    "    \"for i, ax in enumerate(axs):\\n\",\n",
    "    \"    ax.imshow(X_test[i].squeeze(), cmap='gray')\\n\",\n",
    "    \"    ax.set_title(['Horizontal','Vertical'][y_test[i]])\\n\",\n",
    "    \"    ax.axis('off')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 2. Average Image per Class\\n\",\n",
    "    \"avg_h = np.mean(X_train[y_train==0], axis=0).squeeze()\\n\",\n",
    "    \"avg_v = np.mean(X_train[y_train==1], axis=0).squeeze()\\n\",\n",
    "    \"fig, ax = plt.subplots(1,2, figsize=(8,4))\\n\",\n",
    "    \"ax[0].imshow(avg_h, cmap='hot'); ax[0].set_title('Avg Horizontal')\\n\",\n",
    "    \"ax[1].imshow(avg_v, cmap='hot'); ax[1].set_title('Avg Vertical')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 3. Pixel Intensity Distribution\\n\",\n",
    "    \"plt.hist(X_train[y_train==0].flatten(), alpha=0.7, label='Horizontal', bins=30)\\n\",\n",
    "    \"plt.hist(X_train[y_train==1].flatten(), alpha=0.7, label='Vertical', bins=30)\\n\",\n",
    "    \"plt.legend(); plt.title('Pixel Intensity Distribution'); plt.show()\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\"name\": \"python3\", \"display_name\": \"Python 3\"},\n",
    "  \"language_info\": {\"name\": \"python\"}\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
